{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2$^2$\n",
    "\n",
    "REVISIONS|\n",
    "---------|------------------------------------------------\n",
    "2018-1218|CEF, initial.                  \n",
    "2019-0131|CEF, spell checked and update. \n",
    "\n",
    "## Statistics\n",
    "\n",
    "### Mean and Variance\n",
    "\n",
    "The mean and variance (and hence the standard deviation) for a random variable $X$ can for a population of $N$ samples be estimated as\n",
    "\n",
    "$$\n",
    "    \\newcommand\\rem[1]{}\n",
    "    \\rem{ITMAL: CEF def and LaTeX commands, rember: no newlines in defs}\n",
    "    \\newcommand\\eq[2]{#1 &=& #2\\\\}\n",
    "    \\newcommand\\ar[2]{\\begin{array}{#1}#2\\end{array}}\n",
    "    \\newcommand\\ac[2]{\\left[\\ar{#1}{#2}\\right]}\n",
    "    \\newcommand\\st[1]{_{\\mbox{\\scriptsize #1}}}\n",
    "    \\newcommand\\norm[1]{{\\cal L}_{#1}}\n",
    "    \\newcommand\\obs[2]{#1_{\\mbox{\\scriptsize obs}}^{\\left(#2\\right)}}\n",
    "    \\newcommand\\diff[1]{\\mbox{d}#1}\n",
    "    \\newcommand\\pown[1]{^{(#1)}}\n",
    "    \\def\\pownn{\\pown{n}}\n",
    "    \\def\\powni{\\pown{i}}\n",
    "    \\def\\powtest{\\pown{\\mbox{\\scriptsize test}}}\n",
    "    \\def\\powtrain{\\pown{\\mbox{\\scriptsize train}}}\n",
    "    \\def\\bX{\\mathbf{X}}\n",
    "    \\def\\bx{\\mathbf{x}}\n",
    "    \\def\\bw{\\mathbf{w}}\n",
    "    \\def\\by{\\mathbf{y}}\n",
    "    \\def\\bz{\\mathbf{z}}\n",
    "    \\def\\btheta{{\\boldsymbol\\theta}}\n",
    "    \\def\\half{\\frac{1}{2}}\n",
    "    \\begin{array}{rl}\n",
    "        E[X] &= \\frac{1}{N} \\sum_{k=1}^N X_k\\\\\n",
    "             &= \\mu_X\\\\\n",
    "        V[X] &= E[(X_k -E[X])(X_k -E[X])] \\\\\n",
    "             &= E[X_k X_k] - E[X]^2\\\\\n",
    "             &= \\left( \\frac{1}{N} \\sum_{k=1}^N X_k X_k \\right) - \\mu_X^2\\\\\n",
    "             &= \\sigma_X^2\\\\\n",
    "        \\sigma & = \\sqrt{V}\n",
    "    \\end{array}\n",
    "$$\n",
    "\n",
    "Notice that the last $1/N$ factor most often appears as $1/(N-1)$ for the variance estimation.  When using the factor is $1/(N-1)$, $\\hat V$ is said to be the best unbiased estimator, when it is $1/N$ it will be biased, both assuming an underlying normal distribution. Anyway, for large $N$ this factor has less effect.\n",
    "\n",
    "#### Qa Create a mean and standard deviation function for some input data\n",
    "\n",
    "Your python function should be named ```MeanAndVariance()```, it takes a vector as input parameter, and returns TWO parameters, namely mean and variance. \n",
    "\n",
    "Python allows for return of zero, one, or more parameters from a function, without having to place, say two output parameters in a tuple, like in C++ ```return make_pair<float,float>(mean, variance)```.\n",
    "\n",
    "Test it via the ```y``` input and test-vectors below.\n",
    "\n",
    "Extend it to handle both biased and un-biased estimators, and test via the test-vectors below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qa...\n",
    "\n",
    "#def MeanAndVariance(x):    \n",
    "    # Your impl here\n",
    "\n",
    "\n",
    "# Test vectors: mean and variance calc\n",
    "y = np.array([1,2,3,4])\n",
    "m, v=MeanAndVariance(y)\n",
    "\n",
    "expected_m=2.5\n",
    "expected_v=3.75\n",
    "expected_v2=1.25\n",
    "\n",
    "print(\"m=\",m,\", diff=\",m-expected_m)\n",
    "print(\"v=\",v,\", diff=\",v-expected_v)\n",
    "\n",
    "m, v=MeanAndVariance(y)\n",
    "\n",
    "print(\"m=\",m,\", diff=\",m-expected_m)\n",
    "print(\"v=\",v,\", diff=\",v-expected_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Auto- and Cross-covariance in Matrix Notation\n",
    "\n",
    "Now let's goto full matrix notation for the covariance. For a data matrix $\\bX$  \n",
    "\n",
    "$$\n",
    "    \\bX = \\ac{cccc}{\n",
    "        x_1^{(1)} & x_2^{(1)} & \\cdots & x_d^{(1)} \\\\\n",
    "        x_1^{(2)} & x_2^{(2)} & \\cdots & x_d^{(2)}\\\\\n",
    "        \\vdots \\\\\n",
    "        x_1^{(n)} & x_2^{(n)} & \\cdots & x_d^{(n)}\\\\\n",
    "    }\n",
    "$$\n",
    "\n",
    "the autoâ€“covariance matrix can be expressed as\n",
    "\n",
    "$$\n",
    "  \\ar{ll}{\n",
    "       \\Sigma(\\bX) &= \\mbox{cov}(\\bX,\\bX)\\\\\n",
    "        &= E\\left[(\\bX-\\mu_\\bX)(\\bX-\\mu_\\bX)^T \\right]\\\\\n",
    "        &= E\\left[ \\bX\\bX^T \\right] - E[\\bX]E[\\bX]^T\\\\\n",
    "        &= E\\left[ \\bX\\bX^T \\right] - \\mu_\\bX\\mu_\\bX^T\n",
    "   }\n",
    "   \\def\\bZ{\\mathbf{Z}}\n",
    "$$\n",
    "\n",
    "with implicit $1/N$ factor here (inside the first $E[\\cdot]$), so the definition is a biased covariance. You may opt to use the factor $1/(N-1)$ instead.\n",
    "\n",
    "\n",
    "For yet another data matrix $\\bZ $ the cross-covariance matrix is given by\n",
    "\n",
    "$$\n",
    "  \\ar{ll}{\n",
    "       \\Sigma(\\bX,\\bZ) &= \\mbox{cov}(\\bX,\\bZ)\\\\\n",
    "        &= E\\left[(\\bX-\\mu_\\bX)(\\bZ-\\mu_\\bZ)^T \\right]\\\\\n",
    "        &= E\\left[ \\bX\\bZ^T \\right] - E[\\bX]E[\\bZ]^T\\\\\n",
    "        &= E\\left[ \\bX\\bZ^T \\right] - \\mu_\\bX\\mu_\\bZ^T\n",
    "   }\n",
    "$$\n",
    "\n",
    "\n",
    "#### Qb Create a function that generates the covariance matrix $\\Sigma(\\bX)$.\n",
    "\n",
    "Create the function from scratch or find some suitable implementation on the net. \n",
    "\n",
    "Direct use of `numpy.cov` (or other libs) not permitted, though it could serve as a test-stub.  Be very careful regarding the normalization factor when comparing with numpy's or matlabs covar functions. If you are going to use `numpy.cov` for cross-testing, be sure to read up on its `rowvar` parameter!  \n",
    "\n",
    "Make some suitable test data, perhaps share a test-stub with another ITMAL group.\n",
    "\n",
    "Explain the elements in the $\\Sigma$ matrix, what are the diagonal elements $\\Sigma_{ii}$, and what does off-diagonal elements, $\\Sigma_{ij}$ for $i \\neq j$ represent?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qb..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson's r\n",
    "\n",
    "The standard correlation, or Pearson's r, is given by the 'normalized' correlation matrix\n",
    "\n",
    "$$\n",
    "    \\rho(\\mathbf{X},\\mathbf{Y}) = \\frac{cov(\\mathbf{X},\\mathbf{Y})}{\\sigma(\\mathbf{X})\\sigma(\\mathbf{Y})}\n",
    "$$\n",
    "\n",
    "The (dimensionless) Pearson's r is used in [HOML] and is somewhat similar to the (also dimensionless) $R^2$ score we used last time. \n",
    "\n",
    "Let's try to implement the Pearsons's r now...\n",
    "\n",
    "#### Qc Create a Pearson's r function\n",
    "\n",
    "Again, create some test data, and implement your own function or get inspiration by searching the net for code.\n",
    "\n",
    "You need a full implementation, again not use of libs; so direct use of `numpy.corrcoef` not permitted. But it will serve as a good test function...\n",
    "\n",
    "Write a short description of Pearson's r, giving is range (possible min/max values) and a description of what they mean, and classify it as being a loss/scoring function. \n",
    "\n",
    "OPTIONAL: try to re-create some of the data for the plots in figure 2-14 [HOML], and run your Pearson's r function on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qc..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
