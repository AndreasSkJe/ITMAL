{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lession 2$^2$\n",
    "\n",
    "## Statistics\n",
    "\n",
    "### Mean and Variance\n",
    "\n",
    "The mean and variance (and hence the standard deviation) for a random variable $X$ can for a population of $N$ samles be estimated as\n",
    "\n",
    "$$\n",
    "    \\begin{array}{ll}\n",
    "        \\hat{E}\\left[X\\right] &= \\frac{1}{N} \\sum_{k=1}^N X_k\\\\\n",
    "        \\hat{V}(X) &= \\left( \\frac{1}{N} \\sum_{k=1}^N X_k X_k \\right) \n",
    "                - E\\left[X\\right]^2\\\\\n",
    "        \\hat{\\sigma} & = \\sqrt{\\hat V}\n",
    "    \\end{array}\n",
    "$$\n",
    "\n",
    "Notice that the factor $1/N$ sometimes appears as $1/(N-1)$ for the variance estimation. \n",
    "\n",
    "When the factor is $1/(N-1)$ $\\hat V$ is said to be the best unbiased estimater, when it is $1/N$ it will be biased, both assuming a underlying normal distribution. Anyway, for large $N$ this factor has less effect.\n",
    "\n",
    "#### Qa Create a mean and standard deviation function for some input data\n",
    "\n",
    "Test it via the ```y``` input and test-vectors below.\n",
    "\n",
    "Extend it to handle both biased and un-biased estimators, and test via the test-vectors below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m= 2.5 , diff= 0.0\n",
      "v= 3.75 , diff= 0.0\n",
      "m= 2.5 , diff= 0.0\n",
      "v= 1.25 , diff= 0.0\n"
     ]
    }
   ],
   "source": [
    "#def MeanAndVariance(x,biasedvar=True):    \n",
    "    # Your impl here\n",
    "\n",
    "\n",
    "# Test vectors for mean and variance calc\n",
    "\n",
    "y = np.array([1,2,3,4])\n",
    "m, v=MeanAndVariance(y,biasedvar=False)\n",
    "\n",
    "expected_m=2.5\n",
    "expected_v=3.75\n",
    "expected_v2=1.25\n",
    "\n",
    "print(\"m=\",m,\", diff=\",m-expected_m)\n",
    "print(\"v=\",v,\", diff=\",v-expected_v)\n",
    "\n",
    "m, v=MeanAndVariance(y, biasedvar=True)\n",
    "\n",
    "print(\"m=\",m,\", diff=\",m-expected_m)\n",
    "print(\"v=\",v,\", diff=\",v-expected_v2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance\n",
    "\n",
    "The covariance for some real-valued random variable-vectors $\\mathbf x$ and $\\mathbf y$, the  cross covariance is given by \n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{array}{ll}\n",
    "    cov(\\mathbf{x},\\mathbf{y}) &=\n",
    "       E\\left[ (\\mathbf{x} - E\\left[ \\mathbf{x} \\right])\n",
    "               (\\mathbf{y} - E\\left[ \\mathbf{y} \\right]  )^T \\right]\\\\\n",
    "      & = E\\left[ \\mathbf{xy^T}\\right] - E\\left[ \\mathbf{x}\\right]E\\left[ \\mathbf{y^T}\\right]\n",
    "    \\end{array}\n",
    "\\end{equation*}\n",
    "    \n",
    "For the data matrix $\\mathbf X$ \n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{X} =\n",
    "    \\left[\n",
    "    \\begin{array}{cccc}\n",
    "        x_1^{(1)} & x_2^{(1)} & \\cdots & x_d^{(1)} \\\\\n",
    "        x_1^{(2)} & x_2^{(2)} & \\cdots & x_d^{(2)}\\\\\n",
    "        \\vdots \\\\\n",
    "        x_1^{(n)} & x_2^{(n)} & \\cdots & x_d^{(n)}\\\\\n",
    "    \\end{array}\n",
    "    \\right]\n",
    "\\end{equation*}\n",
    "\n",
    "the varianceâ€“covariance matrix is just\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{array}{ll}\n",
    "        \\Sigma(\\mathbf{x}) &= cov(\\mathbf{x},\\mathbf{x})\\\\\n",
    "         &= E\\left[ \\mathbf{xx^T}\\right] - E\\left[ \\mathbf{x}\\right]E\\left[ \\mathbf{x} \\right]^T\\\\\n",
    "    \\end{array}\n",
    "\\end{equation*}\n",
    "\n",
    "that for $N$ data samples and a data sample row vector $\\mathbf{x}^{(k)} = $ can be estimated via\n",
    "\n",
    "$$\n",
    "    \\begin{array}{ll}\n",
    "        \\hat{E}\\left[ \\mathbf{x} \\right] &= \\frac{1}{N} \\sum_{k=1}^N \\mathbf{x}^{(k)}\\\\\n",
    "        \\hat{\\Sigma}(\\mathbf{x})  &= \\left( \\frac{1}{N} \\sum_{k=1}^N \\mathbf{x}^{(k)} \n",
    "            \\left( \\mathbf{x}^{(k)}\\right)^T \\right) \n",
    "              - E\\left[ \\mathbf{x}\\right]E\\left[ \\mathbf{x} \\right]^T\n",
    "    \\end{array}\n",
    "$$\n",
    "\n",
    "using the biased variance estimator, and hence a factor of $1/N$ instead of $1/(N-1)$\n",
    "\n",
    "#### Q b Create a function that generates the covariance matix $\\Sigma(\\mathbf X)$.\n",
    "\n",
    "### Pearson's r\n",
    "\n",
    "The standard correlation, or Pearson's r, is given by the 'normalized' correlation matrix\n",
    "\n",
    "$$\n",
    "    \\rho(\\mathbf{X},\\mathbf{Y}) = \\frac{cov(\\mathbf{X},\\mathbf{Y})}{\\sigma(\\mathbf{X})\\sigma(\\mathbf{Y})}\n",
    "$$\n",
    "\n",
    "#### Qc Create a Pearson's r function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "% reset -f\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y = np.array([1,2,3,4]) # NOTE:  you'll need this later\n",
    "\n",
    "x1 = np.array([ 0, 0, 0])\n",
    "x2 = np.array([ 1, 0, 0])\n",
    "x3 = np.array([ 1, 1, 0])\n",
    "x4 = np.array([ 1, 0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
